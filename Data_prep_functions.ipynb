{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_prep_functions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcsjyqOFNOqHVT2iP/JmBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eternallysunny/ELTE_AI-ML_Final_Project/blob/main/Data_prep_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0afc67d1-5648-41c6-8fba-ea609cffa9e4"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l5xs0jZQgg89",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "9e4a0cab-fb6b-4073-c3d7-9cf519ba7ee3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting labelme\n",
            "  Downloading labelme-5.0.1.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 6.8 MB/s \n",
            "\u001b[?25hCollecting imgviz>=0.11\n",
            "  Downloading imgviz-1.5.0.tar.gz (7.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7 MB 22.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib<3.3 in /usr/local/lib/python3.7/dist-packages (from labelme) (3.2.2)\n",
            "Collecting natsort>=7.1.0\n",
            "  Downloading natsort-8.1.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from labelme) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=2.8 in /usr/local/lib/python3.7/dist-packages (from labelme) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from labelme) (3.13)\n",
            "Requirement already satisfied: qtpy!=1.11.2 in /usr/local/lib/python3.7/dist-packages (from labelme) (2.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from labelme) (1.1.0)\n",
            "Collecting PyQt5!=5.15.3,!=5.15.4\n",
            "  Downloading PyQt5-5.15.6-cp36-abi3-manylinux1_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<3.3->labelme) (4.2.0)\n",
            "Collecting PyQt5-Qt5>=5.15.2\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 93 kB/s \n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n",
            "  Downloading PyQt5_sip-12.10.1-cp37-cp37m-manylinux1_x86_64.whl (338 kB)\n",
            "\u001b[K     |████████████████████████████████| 338 kB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<3.3->labelme) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy!=1.11.2->labelme) (21.3)\n",
            "Building wheels for collected packages: labelme, imgviz\n",
            "  Building wheel for labelme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for labelme: filename=labelme-5.0.1-py3-none-any.whl size=1466204 sha256=7f6744a3d568563d5054b61d50b38c21c2dd97e2a984b4a78eb65712ae23433e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/f1/e1/84b4d6e95299dbc58c1616c63622624e39643ee591866cfd1e\n",
            "  Building wheel for imgviz (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgviz: filename=imgviz-1.5.0-py3-none-any.whl size=7680458 sha256=ecbf93e776b356f85a3902464c5713e3cdd3f106b5db37b1c5c44273f25996aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/36/f3/3c810b6e34387a0307f93d39805fa653742897568f5a3e8080\n",
            "Successfully built labelme imgviz\n",
            "Installing collected packages: PyQt5-sip, PyQt5-Qt5, PyQt5, natsort, imgviz, labelme\n",
            "  Attempting uninstall: natsort\n",
            "    Found existing installation: natsort 5.5.0\n",
            "    Uninstalling natsort-5.5.0:\n",
            "      Successfully uninstalled natsort-5.5.0\n",
            "Successfully installed PyQt5-5.15.6 PyQt5-Qt5-5.15.2 PyQt5-sip-12.10.1 imgviz-1.5.0 labelme-5.0.1 natsort-8.1.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install labelme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dbaf383-02c9-448b-b5a7-e811ce7a5d49"
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skimage.io as io\n",
        "import labelme\n",
        "import json\n",
        "import random\n",
        "import cv2\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Add, Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D, ZeroPadding2D, Activation, concatenate, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "### For visualizing the outputs ###\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33726bdf-98e9-472b-bdb3-98e6dc5bb5ae",
        "tags": []
      },
      "source": [
        "# Data loader and visualization function definitions\n",
        "\n",
        "https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-2-of-2-c0d1f593096a\n",
        "\n",
        "https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047\n",
        "\n",
        "https://github.com/virafpatrawala/COCO-Semantic-Segmentation/blob/master/COCOdataset_SemanticSegmentation_Demo.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f1fe81b-a021-4928-96c1-548d3d780eea"
      },
      "outputs": [],
      "source": [
        "def filterDataset(folder, classes=None, mode='train'):    \n",
        "    # initialize COCO api for instance annotations\n",
        "    annFile = '{}/annotations/instances_{}2014.json'.format(folder, mode)\n",
        "    coco = COCO(annFile)\n",
        "    \n",
        "    images = []\n",
        "    if classes!=None:\n",
        "        # iterate for each individual class in the list\n",
        "        for className in classes:\n",
        "            # get all images containing given categories\n",
        "            catIds = coco.getCatIds(catNms=className)\n",
        "            imgIds = coco.getImgIds(catIds=catIds)\n",
        "            images += coco.loadImgs(imgIds)\n",
        "    \n",
        "    else:\n",
        "        imgIds = coco.getImgIds()\n",
        "        images = coco.loadImgs(imgIds)\n",
        "    \n",
        "    # Now, filter out the repeated images\n",
        "    unique_images = []\n",
        "    for i in range(len(images)):\n",
        "        if images[i] not in unique_images:\n",
        "            unique_images.append(images[i])\n",
        "            \n",
        "    random.shuffle(unique_images)\n",
        "    dataset_size = len(unique_images)\n",
        "    \n",
        "    return unique_images, dataset_size, coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1b49c63-c4c2-437c-a915-1c1db1e06923"
      },
      "outputs": [],
      "source": [
        "def getClassName(classID, cats):\n",
        "    for i in range(len(cats)):\n",
        "        if cats[i]['id']==classID:\n",
        "            return cats[i]['name']\n",
        "    return None\n",
        "\n",
        "def getImage(imageObj, img_folder, input_image_size):\n",
        "    # Read and normalize an image\n",
        "    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
        "    # Resize\n",
        "    train_img = cv2.resize(train_img, input_image_size)\n",
        "    if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n",
        "        return train_img\n",
        "    else: # To handle a black and white image, increase dimensions to 3\n",
        "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
        "        return stacked_img\n",
        "    \n",
        "def getNormalMask(imageObj, classes, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    cats = coco.loadCats(catIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        className = getClassName(anns[a]['category_id'], cats)\n",
        "        pixel_value = classes.index(className)+1\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask  \n",
        "    \n",
        "def getBinaryMask(imageObj, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a]), input_image_size)\n",
        "        \n",
        "        #Threshold because resizing may cause extraneous values\n",
        "        new_mask[new_mask >= 0.5] = 1\n",
        "        new_mask[new_mask < 0.5] = 0\n",
        "\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask\n",
        "\n",
        "\n",
        "def dataGeneratorCoco(images, classes, coco, folder, \n",
        "                      input_image_size=(224,224), batch_size=4, mode='train', mask_type='binary'):\n",
        "    \n",
        "    img_folder = '{}/images/{}'.format(folder, mode)\n",
        "    dataset_size = len(images)\n",
        "    catIds = coco.getCatIds(catNms=classes)\n",
        "    \n",
        "    c = 0\n",
        "    while(True):\n",
        "        img = np.zeros((batch_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n",
        "        mask = np.zeros((batch_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n",
        "\n",
        "        for i in range(c, c+batch_size): #initially from 0 to batch_size, when c = 0\n",
        "            imageObj = images[i]\n",
        "            \n",
        "            ### Retrieve Image ###\n",
        "            train_img = getImage(imageObj, img_folder, input_image_size)\n",
        "            \n",
        "            ### Create Mask ###\n",
        "            if mask_type==\"binary\":\n",
        "                train_mask = getBinaryMask(imageObj, coco, catIds, input_image_size)\n",
        "            \n",
        "            elif mask_type==\"normal\":\n",
        "                train_mask = getNormalMask(imageObj, classes, coco, catIds, input_image_size)                \n",
        "            \n",
        "            # Add to respective batch sized arrays\n",
        "            img[i-c] = train_img\n",
        "            mask[i-c] = train_mask\n",
        "            \n",
        "        c+=batch_size\n",
        "        if(c + batch_size >= dataset_size):\n",
        "            c=0\n",
        "            random.shuffle(images)\n",
        "        yield img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e13e9c2-6371-4e8d-aaa6-c15dfc3fe2fc"
      },
      "outputs": [],
      "source": [
        "def visualizeGenerator(gen):\n",
        "    img, mask = next(gen)\n",
        "    \n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    outerGrid = gridspec.GridSpec(1, 2, wspace=0.1, hspace=0.1)\n",
        "    \n",
        "    for i in range(2):\n",
        "        innerGrid = gridspec.GridSpecFromSubplotSpec(2, 2,\n",
        "                        subplot_spec=outerGrid[i], wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for j in range(4):\n",
        "            ax = plt.Subplot(fig, innerGrid[j])\n",
        "            if(i==1):\n",
        "                ax.imshow(img[j])\n",
        "            else:\n",
        "                ax.imshow(mask[j][:,:,0])\n",
        "                \n",
        "            ax.axis('off')\n",
        "            fig.add_subplot(ax)        \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc35b148-93fc-4d49-afed-8de5cda8f478"
      },
      "outputs": [],
      "source": [
        "# Load, mask and visualize test data (functions)\n",
        "def getTestImages(imageObj, imageFolder, input_image_size):     \n",
        "    # Read and normalize data\n",
        "    train_image = io.imread(imageFolder + '/' + imageObj + '.jpg')/255.0\n",
        "    # Resize images\n",
        "    train_image = cv2.resize(train_image, input_image_size)\n",
        "    if (len(train_image.shape)==3 and train_image.shape[2]==3):  # If it is an RGB 3 channel image\n",
        "        return train_image\n",
        "    else: # If it is a black and white image - to increase dimensions to 3\n",
        "        stacked_image = np.stack((train_image,)*3, axis=-1)\n",
        "        return stacked_image\n",
        "    \n",
        "def getTestBinaryMask(imageObj, annotFolder, input_image_size):\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    # Load masks from .json files, created with labelme API independently\n",
        "    with open(annotFolder + '/' + imageObj + '.json', \"r\", encoding=\"utf-8\") as f:\n",
        "        dj = json.load(f)\n",
        "        mask = labelme.utils.shape_to_mask((dj['imageHeight'],\n",
        "                                                dj['imageWidth']),\n",
        "                                                dj['shapes'][0]['points'], \n",
        "                                                shape_type=None, \n",
        "                                                line_width=1, \n",
        "                                                point_size=1)\n",
        "    mask_img = mask.astype('float32')\n",
        " \n",
        "    new_mask = cv2.resize(mask_img, input_image_size)\n",
        "    # Threshold because resizing may cause extraneous values\n",
        "    new_mask[new_mask >= 0.5] = 1\n",
        "    new_mask[new_mask < 0.5] = 0\n",
        "        \n",
        "    train_mask = np.maximum(new_mask, train_mask)\n",
        "    # Add extra dimensions for parity with train_image size (h * w * 3)\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask\n",
        "\n",
        "def dataGeneratorTest(imgList, imageFolder, annotFolder, input_image_size):\n",
        "\n",
        "    dataset_size = len(imgList)\n",
        "    \n",
        "    img = np.zeros((dataset_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n",
        "    mask = np.zeros((dataset_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n",
        "    \n",
        "    for i in range(0, dataset_size):\n",
        "        imageObj = imgList[i]\n",
        "        \n",
        "        train_img = getTestImages(imageObj, imageFolder, input_image_size)\n",
        "        \n",
        "        train_mask = getTestBinaryMask(imageObj, annotFolder, input_image_size)\n",
        "\n",
        "        img[i] = train_img\n",
        "        mask[i] = train_mask\n",
        "        \n",
        "    return img, mask \n",
        "\n",
        "def visualizeTestData(images, masks):\n",
        "    fig = plt.figure(figsize = (35, 10))\n",
        "    outerGrid = gridspec.GridSpec(1, 2, wspace = 0.1, hspace = 0.1)\n",
        "    \n",
        "    for i in range(2):\n",
        "        innerGrid = gridspec.GridSpecFromSubplotSpec(2, 4, subplot_spec = outerGrid[i], \n",
        "                                                     wspace = 0.025, hspace = 0.025)\n",
        "        for j in range(8):\n",
        "            ax = plt.Subplot(fig, innerGrid[j])\n",
        "            if (i==1):\n",
        "                ax.imshow(images[j])\n",
        "            else:\n",
        "                ax.imshow(masks[j][:, :, 0])\n",
        "                \n",
        "            ax.axis('off')\n",
        "            fig.add_subplot(ax)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7868054c-ec65-451e-9519-9fb5a565f8aa"
      },
      "outputs": [],
      "source": [
        "def visualizeTestPredictions(images, masks, pred):\n",
        "    fig = plt.figure(figsize = (35, 10))\n",
        "    outerGrid = gridspec.GridSpec(1, 3, wspace = 0.1, hspace = 0.1)\n",
        "    \n",
        "    for i in range(3):\n",
        "        innerGrid = gridspec.GridSpecFromSubplotSpec(2, 4, subplot_spec = outerGrid[i], \n",
        "                                                     wspace = 0.025, hspace = 0.025)\n",
        "        for j in range(8):\n",
        "            ax = plt.Subplot(fig, innerGrid[j])\n",
        "            if (i==0):\n",
        "                ax.imshow(images[j])\n",
        "            elif (i==1):\n",
        "                ax.imshow(masks[j][:, :, 0])\n",
        "            else:\n",
        "                ax.imshow(pred[j][:, :, 0])\n",
        "                \n",
        "            ax.axis('off')\n",
        "            fig.add_subplot(ax)\n",
        "    plt.show()"
      ]
    }
  ]
}